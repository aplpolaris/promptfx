# Library of OpenAI Models
# See https://platform.openai.com/docs/models
---
audio: [ whisper-1 ]
chat: [ gpt-3.5-turbo, gpt-4-turbo, gpt-4 ]
completion: [ gpt-3.5-turbo-instruct, davinci-002, babbage-002 ]
embeddings: [ text-embedding-ada-002, text-embedding-3-large, text-embedding-3-small ]
moderation: [ text-moderation-latest, text-moderation-stable ]
tts: [ tts-1, tts-1-hd ]
image_generator: [ dall-e-2, dall-e-3 ]
vision_language: [ gpt-4o-mini, gpt-4o ]

models:

  GPT-4:

    - id: gpt-4o
      name: GPT-4o
      type: TEXT_VISION_CHAT
      inputs: [ text, image ]
      outputs: [ text ]
      source: OpenAI
      description: >
        GPT-4o (“o” for “omni”) is our versatile, high-intelligence flagship model.
        It accepts both text and image inputs, and produces text outputs (including Structured Outputs).
      lifecycle: PRODUCTION_ALIAS
      totalTokenLimit: 128000
      outputTokenLimit: 16384
      snapshots: [ '2024-05-13' ]

    - id: chatgpt-4o-latest
      name: ChatGPT 4o
      type: TEXT_VISION_CHAT
      inputs: [ text, image ]
      outputs: [ text ]
      source: OpenAI
      description: >
        Latest GPT-4o model used in ChatGPT
      lifecycle: PRODUCTION_ALIAS
      totalTokenLimit: 128000
      outputTokenLimit: 16384
      snapshots: [ '2024-05-13' ]

    - id: gpt-4o-mini
      name: GPT-4o Mini
      type: TEXT_VISION_CHAT
      inputs: [ text, image ]
      outputs: [ text ]
      source: OpenAI
      description: >
        GPT-4o mini (“o” for “omni”) is a fast, affordable small model for focused tasks.
        It accepts both text and image inputs, and produces text outputs (including Structured Outputs).
        It is ideal for fine-tuning, and model outputs from a larger model like GPT-4o can be distilled to GPT-4o-mini to produce similar results at lower cost and latency.
      lifecycle: PRODUCTION_ALIAS
      totalTokenLimit: 128000
      outputTokenLimit: 16384

    - id: gpt-4-turbo
      name: GPT-4-turbo
      type: TEXT_VISION_CHAT
      inputs: [ text, image ]
      outputs: [ text ]
      source: OpenAI
      description: >
        GPT-4 is an older version of a high-intelligence GPT model, usable in Chat Completions.
        The knowledge cutoff for the latest GPT-4 Turbo version is December, 2023.
      lifecycle: PRODUCTION_ALIAS
      totalTokenLimit: 128000
      outputTokenLimit: 4096
      snapshots: [ '2024-04-09', 'preview' ]

    - id: gpt-4
      name: GPT-4
      type: TEXT_CHAT
      inputs: [ text, image ]
      outputs: [ text ]
      source: OpenAI
      description: >
        GPT-4 is an older version of a high-intelligence GPT model, usable in Chat Completions.
        The knowledge cutoff for the latest GPT-4 Turbo version is December, 2023.
      lifecycle: PRODUCTION_ALIAS
      totalTokenLimit: 8192
      outputTokenLimit: 8192
      snapshots: [ '0613', '1106-preview' ]

  GPT-4 Reasoning:

    - id: o1
      name: GPT o1 Reasoning
      type: TEXT_VISION_CHAT
      inputs: [ text, image ]
      outputs: [ text ]
      source: OpenAI
      description: >
        The o1 series of models are trained with reinforcement learning to perform complex reasoning.
        o1 models think before they answer, producing a long internal chain of thought before responding to the user.
        o1: reasoning model designed to solve hard problems across domains
      lifecycle: PRODUCTION_ALIAS
      totalTokenLimit: 200000
      outputTokenLimit: 100000

    - id: o1-mini
      name: GPT o1-mini Reasoning
      type: TEXT_CHAT
      inputs: [ text ]
      outputs: [ text ]
      source: OpenAI
      description: >
        The o1 series of models are trained with reinforcement learning to perform complex reasoning.
        o1 models think before they answer, producing a long internal chain of thought before responding to the user.
        o1-mini: fast and affordable reasoning model for specialized tasks
      lifecycle: PRODUCTION_ALIAS
      totalTokenLimit: 128000
      outputTokenLimit: 65536

  GPT-3.5:

    - id: gpt-3.5-turbo
      name: GPT-3.5 Turbo
      type: TEXT_CHAT
      source: OpenAI
      description: >
        GPT-3.5 with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more.
      lifecycle: PRODUCTION_ALIAS
      inputs: [ text ]
      outputs: [ text ]
      totalTokenLimit: 16385
      outputTokenLimit: 4096

  Embeddings:

    - id: text-embedding-ada-002
      name: Ada Text Embeddings
      type: TEXT_EMBEDDING
      source: OpenAI
      description: Most capable 2nd generation embedding model, replacing 16 first generation models
      lifecycle: PRODUCTION
      inputs: [ text ]
      outputs: [ embedding ]
      outputDimension: 1536

    - id: text-embedding-3-large
      name: Ada Text Embeddings
      type: TEXT_EMBEDDING
      source: OpenAI
      description: Most capable embedding model for both english and non-english tasks
      lifecycle: PRODUCTION
      inputs: [ text ]
      outputs: [ embedding ]
      outputDimension: 3072

    - id: text-embedding-3-small
      name: Ada Text Embeddings
      type: TEXT_EMBEDDING
      source: OpenAI
      description: Increased performance over 2nd generation ada embedding model
      lifecycle: PRODUCTION
      inputs: [ text ]
      outputs: [ embedding ]
      outputDimension: 1536

  GPT completions:

    - id: gpt-3.5-turbo-instruct
      name: GPT-3.5 Turbo Instruct
      type: TEXT_COMPLETION
      source: OpenAI
      description: >
        Similar capabilities as GPT-3 era models. Compatible with legacy Completions endpoint and not Chat Completions.
      lifecycle: LEGACY
      inputs: [ text ]
      outputs: [ text ]
      totalTokenLimit: 4096
      outputTokenLimit: 4096

    - id: davinci-002
      name: Davinci 2
      type: TEXT_COMPLETION
      source: OpenAI
      lifecycle: LEGACY
      inputs: [ text ]
      outputs: [ text ]
      totalTokenLimit: 16384
      outputTokenLimit: 4096

    - id: babbage-002
      name: Babbage 2
      type: TEXT_COMPLETION
      source: OpenAI
      lifecycle: LEGACY
      inputs: [ text ]
      outputs: [ text ]
      totalTokenLimit: 16384
      outputTokenLimit: 4096

  Image Generation:

    - id: dall-e-3
      name: DALL-E 3
      type: IMAGE_GENERATOR
      source: OpenAI
      lifecycle: PRODUCTION
      inputs: [ text ]
      outputs: [ image ]

    - id: dall-e-2
      name: DALL-E 2
      type: IMAGE_GENERATOR
      source: OpenAI
      lifecycle: PRODUCTION
      inputs: [ text ]
      outputs: [ image ]

  Moderation:

    - id: omni-moderation-latest
      name: Omni Text Moderation (latest)
      type: MODERATION
      source: OpenAI
      lifecycle: PRODUCTION
      inputs: [ text, image ]
      outputs: [ moderation ]
      totalTokenLimit: 32768

    - id: text-moderation-latest
      name: Text Moderation (latest)
      type: MODERATION
      source: OpenAI
      lifecycle: PRODUCTION
      inputs: [ text ]
      outputs: [ moderation ]
      totalTokenLimit: 32768

    - id: text-moderation-stable
      name: Text Moderation (stable)
      type: MODERATION
      source: OpenAI
      lifecycle: PRODUCTION
      inputs: [ text ]
      outputs: [ moderation ]
      totalTokenLimit: 32768

  Speech:

    - id: tts-1
      name: TTS 1
      source: OpenAI
      type: TEXT_TO_SPEECH
      description: TTS 1 optimized for real-time text
      lifecycle: PRODUCTION
      inputs: [ text ]
      outputs: [ audio ]

    - id: tts-1-hd
      name: TTS 1 HD
      type: TEXT_TO_SPEECH
      source: OpenAI
      description: TTS 1 optimized for higher quality audio
      lifecycle: PRODUCTION
      inputs: [ text ]
      outputs: [ audio ]

    - id: whisper-1
      name: Whisper v2-large
      type: SPEECH_TO_TEXT
      source: OpenAI
      description: Whisper speech recognition model, see https://github.com/openai/whisper and https://arxiv.org/abs/2212.04356
      lifecycle: PRODUCTION
      inputs: [ audio ]
      outputs: [ text ]